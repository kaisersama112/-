# 六. 卷积神经网络

​		在前面的章节中，我们遇到过图像数据。这种数据的每个样本都由一个**二维像素网格组成**，每个像素可能是 一个或者多个数值，取决于是黑白还是彩色图像。到目前为止，我们处理这类结构丰富的数据的方式还不够 有效。我们仅仅通过将图像数据展平成一维向量而忽略了每个图像的空间结构信息，再将数据送入一个全连 接的多层感知机中。因为这些网络特征元素的顺序是不变的，因此最优的结果是利用先验知识，即利用相近 像素之间的相互关联性，从图像数据中学习得到有效的模型。

​		**卷积神经网络（convolutional neural network，CNN）**是一类强大的、为处理图像数据而设计的 神经网络。基于卷积神经网络架构的模型在计算机视觉领域中已经占主导地位，当今几乎所有的图像识别、 目标检测或语义分割相关的学术竞赛和商业应用都以这种方法为基础。

​		现代卷积神经网络的设计得益于生物学、群论和一系列的补充实验。**卷积神经网络需要的参数少于全连接架构的网络**，而且卷积也很**容易用GPU并行计算**。卷积神经网络除了能够高效地采样从而获得精确的模型， 还能够高效地计算。



## 1. 从全连接层到卷积

​		多层感知机十分适合处理表格数据，其中行对应样本，列对应特征，**对于表格数据，我们寻找的模式可能涉及特征之间的交互，但是我们不能预先假设任何与特征交互相关的先验结构。此时，多层感 知机可能是最好的选择，然而对于高维感知数据，这种缺少结构的网络可能会变得不实用。**

​		假设我们有一个足够充分的照片数据集，数据集中是拥有标注的照片，每张照片具有百万级像素，这意味着网络的每次输入都有一百万个维度。即使将隐藏层维度降低到1000，这个全连接层也将有106 × 103 = 109个参数。想要训练这个模型将不可实现，因为需要有大量的GPU、分布式优化训练的经验和超乎常人的耐心。 

### 1.1 不变性

​		假设我们想从一张图片中找到某个物体。合理的假设是：无论哪种方法找到这个物体，都应该和物体的位置无关。卷积神经网络正是将空间不变性（spatial invariance） 的这一概念系统化，从而基于这个模型使用较少的参数来学习有用的表示。

	1. 平移不变性（translation invariance）：不管检测对象出现在图像中的哪个位置，神经网络的前面几层 应该对相同的图像区域具有相似的反应，即为“平移不变性”。 
	1. 局部性（locality）：神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔 较远区域的关系，这就是“局部性”原则。最终，可以聚合这些局部特征，以在整个图像级别进行预测。

### 2. 多层感知机的限制

​		首先多层感知机的输入是二位图像**X**,其中隐藏表示**H**在数学上是一个矩阵，在代码中表示为二维张量，其中**X**和**H**具有相同的形状。为了方便理解，我们可以认为，无论是输入还是隐藏表示都拥有空间结构。

​		使用[X]i,j和[H]i,j分别表示输入图像和隐藏表示中位置（i,j）处的像素。为了使每个隐藏神经元都能接收到 每个输入像素的信息，我们将参数从权重矩阵（如同我们先前在多层感知机中所做的那样）替换为四阶权重张量W。假设U包含偏置参数，我们可以将全连接层形式化地表示为

![1.1](https://raw.githubusercontent.com/kaisersama112/typora_image/master/image-20240521164746389.png)



​		其中，从W到V的转换只是形式上的转换，因为在这两个四阶张量的元素之间存在一一对应的关系。我们只需 重新索引下标(k, l)，使k = i + a、l = j + b，由此可得[V]i,j,a,b = [W]i,j,i+a,j+b。索引a和b通过在正偏移和负偏 移之间移动覆盖了整个图像。对于隐藏表示中任意给定位置（i,j）处的像素值[H]i,j，可以通过在x中以(i, j)为 中心对像素进行加权求和得到，加权使用的权重为[V]i,j,a,b。

#### 平移不变性

​		现在引用上述的第一个原则：平移不变性。这意味着检测对象在输入X中的平移，应该仅导致隐藏表示H中的 平移。也就是说，V和U实际上不依赖于(i, j)的值，即[V]i,j,a,b = [V]a,b。并且U是一个常数，比如u。因此，我 们可以简化H定义为：

![1.2](https://raw.githubusercontent.com/kaisersama112/typora_image/master/image-20240521170259338.png)

​		这就是卷积（convolution）。我们是在使用系数[V]a,b对位置(i, j)附近的像素(i + a, j + b)进行加权得到[H]i,j。 注意，[V]a,b的系数比[V]i,j,a,b少很多，因为前者不再依赖于图像中的位置。这就是显著的进步！

#### 局部性

​		现在引用上述的第二个原则：局部性。为了收集用来训练参数[H]i,j的相关信息，我们不应偏离 到距(i, j)很远的地方。这意味着在|a| > ∆或|b| > ∆的范围之外，我们可以设置[V]a,b = 0。因此，我们可以 将[H]i,j重写

![1.3](https://raw.githubusercontent.com/kaisersama112/typora_image/master/image-20240521170709161.png)

​		上述公式表示的是一个卷积层（convolutional layer），而卷积神经网络是包含卷积层的一类特殊的神经网络。**V被称为卷积核（convolution kernel）或者滤波器（filter），亦或简单地称之为该卷积层的权重，通常该权重是可学习的参数**。当图像处理的局部区域很小时，卷积神经网络与多层感知机的训练差异可能是巨大的：以前，多层感知机可能需要数十亿个参数来表示网络中的一层，而现在卷积神经网络通常只需要几百个参数，而且不需要改变输入或隐藏表示的维数。参数大幅减少的代价是，我们的特征现在是平移不变的，并且当确定每个隐藏活性值时，每一层只包含局部的信息。以上所有的权重学习都将依赖于归纳偏置。当这种偏置与现实相符时，我们就能得到样本有效的模型，并且这些模型能很好地泛化到未知数据中。但如果这偏置与现实不符时，比如当图像不满足平移不变时，我们的模型可能难以拟合我们的训练数据。

### 3. 卷积

​		在数学中，两个函数（比如f, g : R d → R）之间的“卷积”被定义为：

![1.4](https://raw.githubusercontent.com/kaisersama112/typora_image/master/image-20240521171041951.png)

​		也就是说，卷积是当把一个函数“翻转”并移位x时，测量f和g之间的重叠。当为离散对象时，积分就变成求 和。例如，对于由索引为Z的、平方可和的、无限维向量集合中抽取的向量，我们得到以下定义：![1.5](https://raw.githubusercontent.com/kaisersama112/typora_image/master/image-20240521171541234.png)

​		对于二维张量，则为f的索引(a, b)和g的索引(i − a, j − b)上的对应加和：![1.6](https://raw.githubusercontent.com/kaisersama112/typora_image/master/image-20240521171600165.png)

​	

### 4. 例

现在我们通过一个例子（沃尔多在哪里？）来说明：

![image-20240521172150681](https://raw.githubusercontent.com/kaisersama112/typora_image/master/image-20240521172150681.png)

​		卷积层根据滤波器V选取给定大小的窗口，并加权处理图片，我们的目标是学习一个模型，以便探测出在“沃尔多”最可能出现的地方。

#### 通道

​		我们知道图像一般具有三个通道（红，绿，蓝），是一个由高度、宽度和颜色组成的三维张量，在上述我们讲述的卷积中式采用的二维张量（i,j）现在我们将他拓展一下为三维张量（i,j,k），由此卷 积相应地调整为[V]a,b,c，而不是[V]a,b。

​		此外，由于输入图像是三维的，我们的隐藏表示H也最好采用三维张量。换句话说，对于每一个空间位置，我 们想要采用一组而不是一个隐藏表示。这样一组隐藏表示可以想象成一些互相堆叠的二维网格。因此，我们 可以把隐藏表示想象为一系列具有二维张量的通道（channel）。这些通道有时也被称为特征映射（feature maps），因为每个通道都向后续层提供一组空间化的学习特征。直观上可以想象在靠近输入的底层，一些通道专门识别边缘，而一些通道专门识别纹理。

​		为了支持输入X和隐藏表示H中的多个通道，我们可以在V中添加第四个坐标，即[V]a,b,c,d。综上所述，![image-20240522161407613](https://raw.githubusercontent.com/kaisersama112/typora_image/master/image-20240522161407613.png)

​		其中隐藏表示H中的索引d表示输出通道，而随后的输出将继续以三维张量H作为输入进入下一个卷积层。所以，上述公式可以定义具有多个通道的卷积层，而其中V是该卷积层的权重。

​		然而，仍有许多问题有待解决。例如，图像中是否到处都有存在沃尔多的可能？如何有效地计算输出层？如何选择适当的激活函数？为了训练有效的网络，如何做出合理的网络设计选择？我们将在本章的其它部分讨论这些问题。



## 2. 图像卷积

​		在上面我们讲述了卷积层的原理，由于卷积神经网络主要设计用来探索图像数据，下面我们将从真实案例进行讲解。

### 2.1 互相关运算

​		严格来说，卷积层是个错误的叫法，因为它所表达的运算其实是互相关运算（cross‐correlation），而不是卷积运算。根据 上一节中的描述，在卷积层中，输入张量和核张量通过互相关运算产生输出张量。

​		首先，我们暂时忽略通道（第三维）这一情况，看看如何处理二维图像数据和隐藏表示。在下图中，输入是高度为3、宽度为3的二维张量（即形状为3 × 3）。卷积核的高度和宽度都是2，而卷积核窗口（或卷积窗口） 的形状由内核的高度和宽度决定（即2 × 2）。

![image-20240522163257646](https://raw.githubusercontent.com/kaisersama112/typora_image/master/image-20240522163257646.png)

​		上述图中： 二维互相关运算。阴影部分是第一个输出元素，以及用于计算输出的输入张量元素和核张量元素： 0 × 0 + 1 × 1 + 3 × 2 + 4 × 3 = 19.

​		在二维互相关运算中，卷积窗口从输入张量的左上角开始，从左到右、从上到下滑动。当卷积窗口滑动到新 一个位置时，包含在该窗口中的部分张量与卷积核张量进行按元素相乘，得到的张量再求和得到一个单一的 标量值，由此我们得出了这一位置的输出张量值。在如上例子中，输出张量的四个元素由二维互相关运算得 到，这个输出高度为2、宽度为2，如下所示：

![image-20240522163735663](https://raw.githubusercontent.com/kaisersama112/typora_image/master/image-20240522163735663.png)

​		注意，输出大小略小于输入大小。这是因为卷积核的宽度和高度大于1，而卷积核只与图像中每个大小完全适 合的位置进行互相关运算。所以，输出大小等于输入大小nh × nw减去卷积核大小kh × kw，即：![image-20240522163816990](https://raw.githubusercontent.com/kaisersama112/typora_image/master/image-20240522163816990.png)

​		这是因为我们需要足够的空间在图像上“移动”卷积核。稍后，我们将看到如何通过在图像边界周围填充零 来保证有足够的空间移动卷积核，从而保持输出大小不变。接下来，我们在corr2d函数中实现如上过程，该 函数接受输入张量X和卷积核张量K，并返回输出张量Y。

```python
"""
互相关公式
(nh − kh + 1) × (nw − kw + 1)
"""


def corr2d(X, K):
    h, w = K.shape
    Y = torch.zeros(X.shape[0] - h + 1, X.shape[1] - w + 1)
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()
    return Y


X = torch.tensor([
    [0.0, 1.0, 2.0],
    [3.0, 4.0, 5.0],
    [6.0, 7.0, 8.0]
])
K = torch.tensor([
    [0.0, 1.0],
    [2.0, 3.0]
])
corr2d(X, K)
```

```cmd
tensor([[19., 25.],
        [37., 43.]])
```

###  2.2 卷积层

​		卷积层对输入和卷积核权重进行互相关运算，并在添加标量偏置之后产生输出。所以，卷积层中的两个被训练的参数是卷积核权重和标量偏置。就像我们之前随机初始化全连接层一样，在训练基于卷积层的模型时， 我们也随机初始化卷积核权重。

​		基于上面定义的corr2d函数实现二维卷积层。在__init__构造函数中，将weight和bias声明为两个模型参数。 前向传播函数调用corr2d函数并添加偏置。

```python
# 卷积层
class ConvNet(nn.Module):
    def __init__(self, kernel_size):
        super(ConvNet, self).__init__()
        self.weight = nn.Parameter(torch.rand(kernel_size))
        self.bias = nn.Parameter(torch.zeros(1))

    def forward(self, x):
        return corr2d(x, self.weight) + self.bias
```

​		高度和宽度分别为h和w的卷积核可以被称为h × w卷积或h × w卷积核。我们也将带有h × w卷积核的卷积层 称为h × w卷积层。



### 2.3 图像中的边缘检测

​		如下是卷积层的一个简单应用：通过找到像素变化的位置，来检测图像中不同颜色的边缘。首先，我们构造 一个6 × 8像素的黑白图像。中间四列为黑色（0），其余像素为白色（1）。

​		接下来，我们构造一个高度为1、宽度为2的卷积核K。当进行互相关运算时，如果水平相邻的两元素相同，则 输出为零，否则输出为非零。

```python
# 图像中目标的边缘检测

X = torch.ones((6, 8))
X[:, 2:6] = 0
print(X)
K = torch.tensor([
    [1.0, -1.0]
])
Y = corr2d(X, K)
print(Y)
```

```cmd
tensor([[1., 1., 0., 0., 0., 0., 1., 1.],
        [1., 1., 0., 0., 0., 0., 1., 1.],
        [1., 1., 0., 0., 0., 0., 1., 1.],
        [1., 1., 0., 0., 0., 0., 1., 1.],
        [1., 1., 0., 0., 0., 0., 1., 1.],
        [1., 1., 0., 0., 0., 0., 1., 1.]])
tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],
        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])
```

​		现在，我们对参数X（输入）和K（卷积核）执行互相关运算。从上面代码输出结果可以看到，输出Y中的1代表从白色到黑色的边 缘，‐1代表从黑色到白色的边缘，其他情况的输出为0。

​		现在我们将输入的二维图像转置，再进行如上的互相关运算。其输出如下，之前检测到的垂直边缘消失了。 不出所料，这个卷积核K只可以检测垂直边缘，无法检测水平边缘。

```python
corr2d(X.t(), K)
```

```cmd
tensor([[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]])
```

### 2.4 学习卷积核

​		如果我们只需寻找黑白边缘，那么以上[1, -1]的边缘检测器足以。然而，当有了更复杂数值的卷积核，或者 连续的卷积层时，我们不可能手动设计滤波器。那么我们是否可以学习由X生成Y的卷积核呢？ 

​		现在让我们看看是否可以通过仅查看“输入‐输出”对来学习由X生成Y的卷积核。我们先构造一个卷积层，并 将其卷积核初始化为随机张量。接下来，在每次迭代中，我们比较Y与卷积层输出的平方误差，然后计算梯度 来更新卷积核。为了简单起见，我们在此使用内置的二维卷积层，并忽略偏置。

```python
# 学习卷积核
# 定义一个二维卷积层 它具有一个输出通道形状为（1，2）的卷积核
conv2d = nn.Conv2d(1, 1, kernel_size=(1, 2), bias=False)

# 这个二维卷积层使用四维输入和输出格式（批量大小、通道、高度、宽度），
# 其中批量大小和通道数都为1
X = X.reshape(1, 1, 6, 8)
Y = Y.reshape(1, 1, 6, 7)
print(X)
print(Y)
lr = 3e-2
for epoch in range(10):
    y_hat = conv2d(X)
    l = (y_hat - Y) ** 2
    conv2d.zero_grad()
    l.sum().backward()
    conv2d.weight.data[:] -= lr * conv2d.weight.grad
    if (epoch + 1) % 2 == 0:
        print(f"Epoch: {epoch},loss: {l.sum():.4f}")
```

```cmd
tensor([[[[1., 1., 0., 0., 0., 0., 1., 1.],
          [1., 1., 0., 0., 0., 0., 1., 1.],
          [1., 1., 0., 0., 0., 0., 1., 1.],
          [1., 1., 0., 0., 0., 0., 1., 1.],
          [1., 1., 0., 0., 0., 0., 1., 1.],
          [1., 1., 0., 0., 0., 0., 1., 1.]]]])
tensor([[[[ 0.,  1.,  0.,  0.,  0., -1.,  0.],
          [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
          [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
          [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
          [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
          [ 0.,  1.,  0.,  0.,  0., -1.,  0.]]]])
Epoch: 1,loss: 4.1193
Epoch: 3,loss: 0.9483
Epoch: 5,loss: 0.2644
Epoch: 7,loss: 0.0875
Epoch: 9,loss: 0.0324
```

```python
conv2d.weight.data.reshape((1, 2))
```

```cmd
tensor([[-0.3554,  0.1154]])
```

通过观察我们可以发现我们学习到的卷积核权重非常接近我们之前定义的卷积核K。

### 2.5 互相关和卷积

​		为了得到正式的卷积运算输出，我们 需要执行严格卷积运算，而不是互相关运算。它们差别不大，我们只需水平和垂 直翻转二维卷积核张量，然后对输入张量执行互相关运算。

​		由于卷积核是从数据中学习到的，因此无论这些层执行严格的卷积运算还是互相关运算，卷 积层的输出都不会受到影响。假设卷积层执行互相关运算并学习卷积核，该卷 、积核在这里由矩阵K表示。假设其他条件不变，当这个层执行严格的卷积时，学习的卷积核K ′在水平和垂直 翻转之后将与K相同。也就是说，当卷积层输入和K ′执行严格卷积运算时，将得到与互相关运算相同的输出。



### 2.6 特征映射和感受野

​		输出的卷积层有时被称为特征映射（feature map），因为它可以被视为一个输入映射到下一层的空间维度的转换器。在卷积神经网络中，对于某一层的任意元素x，其感受野（receptive field）是指在前向传播期间可能影响x计算的所有元素（来自所有先前层）。

​		感受野可能大于输入的实际大小。假设我们给定2 × 2卷积核，阴影输 出元素值19的感受野是输入阴影部分的四个元素。假设之前输出为Y，其大小为2 × 2，现在我们在其后附加 一个卷积层，该卷积层以Y为输入，输出单个元素z。在这种情况下，Y上的z的感受野包括Y的所有四个元素， 而输入的感受野包括最初所有九个输入元素。因此，当一个特征图中的任意元素需要检测更广区域的输入特 征时，我们可以构建一个更深的网络。



## 3. 填充和步幅

​		在前面的例子中，输入的高度和宽度都为3，卷积核的高度和宽度都为2，生成的输出表征的维数 为2 × 2。正如我们在上节中所概括的那样，假设输入形状为nh × nw，卷积核形状为kh × kw，那么输出形 状将是(nh − kh + 1) × (nw − kw + 1)。因此，卷积的输出形状取决于输入形状和卷积核的形状。

​		还有什么因素会影响输出的大小呢？本节我们将介绍填充（padding）和步幅（stride）。假设以下情景：有时，在应用了连续的卷积之后，我们最终得到的输出远小于输入大小。这是由于卷积核的宽度和高度通常大 于1所导致的。比如，一个240 × 240像素的图像，经过10层5 × 5的卷积后，将减少到200 × 200像素。如此一 来，原始图像的边界丢失了许多有用信息。而填充是解决此问题最有效的方法；有时，我们可能希望大幅降 低图像的宽度和高度。例如，如果我们发现原始的输入分辨率十分冗余。步幅则可以在这类情况下提供帮助。



### 3.1 填充

​		在应用多层卷积时，我们常常丢失边缘像素。由于我们通常使用小卷积核，因此对于任何单个卷 积，我们可能只会丢失几个像素。但随着我们应用许多连续卷积层，累积丢失的像素数就多了。解决这个问题的简单方法即为填充（padding）：在输入图像的边界填充元素（通常填充元素是0）。例如：![image-20240523114845612](https://raw.githubusercontent.com/kaisersama112/typora_image/master/image-20240523114845612.png)

​		我们将3 × 3输入填充到5 × 5，那么它的输出就增加为4 × 4。阴影部分是第一个输出元素以及用于输出计算 的输入和核张量元素：0 × 0 + 0 × 1 + 0 × 2 + 0 × 3 = 0。

​		通常，如果我们添加ph行填充（大约一半在顶部，一半在底部）和pw列填充（左侧大约一半，右侧一半），则 输出形状将为![image-20240523114923562](https://raw.githubusercontent.com/kaisersama112/typora_image/master/image-20240523114923562.png)

​		这意味着输出的高度和宽度将分别增加ph和pw。

​		在许多情况下，我们需要设置ph = kh − 1和pw = kw − 1，使输入和输出具有相同的高度和宽度。这样可以在 构建网络时更容易地预测每个图层的输出形状。假设kh是奇数，我们将在高度的两侧填充ph/2行。如果kh是 偶数，则一种可能性是在输入顶部填充⌈ph/2⌉行，在底部填充⌊ph/2⌋行。同理，我们填充宽度的两侧。

​		卷积神经网络中卷积核的高度和宽度通常为奇数，例如1、3、5或7。选择奇数的好处是，保持空间维度的同 时，我们可以在顶部和底部填充相同数量的行，在左侧和右侧填充相同数量的列。

​		 此外，使用奇数的核大小和填充大小也提供了书写上的便利。对于任何二维张量X，当满足：1. 卷积核的大小 是奇数；2. 所有边的填充行数和列数相同；3. 输出与输入具有相同高度和宽度则可以得出：输出Y[i, j]是 通过以输入X[i, j]为中心，与卷积核进行互相关计算得到的。 比如，在下面的例子中，我们创建一个高度和宽度为3的二维卷积层，并在所有侧边填充1个像素。给定高度 和宽度为8的输入，则输出的高度和宽度也是8。

```python
# 填充
import torch
from torch import nn
# 此函数初始化卷积层权重，并对输入和输出提高和缩减相应的维数
def comp_conv2d(conv2d, X):
    # 这里的（1，1）表示批量大小和通道数都是1
    X = X.reshape((1, 1) + X.shape)
    Y = conv2d(X)
    # 省略前两个维度：批量大小和通道
    return Y.reshape(Y.shape[2:])

conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1)
X = torch.rand(size=(8, 8))

comp_conv2d(conv2d, X).shape
```

```cmd
torch.Size([8, 8])
```

​		当卷积核的高度和宽度不同时，我们可以填充不同的高度和宽度，使输出和输入具有相同的高度和宽度。在 如下示例中，我们使用高度为5，宽度为3的卷积核，高度和宽度两边的填充分别为2和1。

```python
conv2d = nn.Conv2d(1, 1, kernel_size=(5, 3), padding=(2, 1))
comp_conv2d(conv2d, X).shape
```

```cmd
torch.Size([8, 8])
```



### 3.2 步幅

​		在计算互相关时，卷积窗口从输入张量的左上角开始，向下、向右滑动。在前面的例子中，我们默认每次滑动 一个元素。但是，有时候为了高效计算或是缩减采样次数，卷积窗口可以跳过中间位置，每次滑动多个元素。

![image-20240523150558749](https://raw.githubusercontent.com/kaisersama112/typora_image/master/image-20240523150558749.png)

​		我们将每次滑动元素的数量称为步幅（stride）。到目前为止，我们只使用过高度或宽度为1的步幅，那么如何 使用较大的步幅呢？图6.3.2是垂直步幅为3，水平步幅为2的二维互相关运算。着色部分是输出元素以及用于 输出计算的输入和内核张量元素：0 × 0 + 0 × 1 + 1 × 2 + 2 × 3 = 8、0 × 0 + 6 × 1 + 0 × 2 + 0 × 3 = 6。

​		可以看到，为了计算输出中第一列的第二个元素和第一行的第二个元素，卷积窗口分别向下滑动三行和向右 滑动两列。但是，当卷积窗口继续向右滑动两列时，没有输出，因为输入元素无法填充窗口（除非我们添加 另一列填充）。

​		通常，当垂直步幅为sh、水平步幅为sw时，输出形状为:

![image-20240523150621268](https://raw.githubusercontent.com/kaisersama112/typora_image/master/image-20240523150621268.png)

​		如果我们设置了ph = kh − 1和pw = kw − 1，则输出形状将简化为⌊(nh + sh − 1)/sh⌋ × ⌊(nw + sw − 1)/sw⌋。 更进一步，如果输入的高度和宽度可以被垂直和水平步幅整除，则输出形状将为(nh/sh) × (nw/sw)。

​		下面，我们将高度和宽度的步幅设置为2，从而将输入的高度和宽度减半。

```python
conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)
comp_conv2d(conv2d, X).shape
```

```cmd
torch.Size([4, 4])
```

​		为了简洁起见，当输入高度和宽度两侧的填充数量分别为ph和pw时，我们称之为填充(ph, pw)。当ph = pw = p时，填充是p。同理，当高度和宽度上的步幅分别为sh和sw时，我们称之为步幅(sh, sw)。特别地，当sh = sw = s时， 我们称步幅为s。默认情况下，填充为0，步幅为1。在实践中，我们很少使用不一致的步幅或填充，也就是说， 我们通常有ph = pw和sh = sw。



## 4. 多输入多输出通道

​		当我们添加通道时，我们的输入和隐藏的表示都变成了三维张量。例如，每个RGB输入图像具有3 × h × w的 形状。我们将这个大小为3的轴称为通道（channel）维度。本节将更深入地研究具有多输入和多输出通道的 卷积核。



### 4.1 多输入通道

​		当输入包含多个通道时，需要构造一个与输入数据具有相同输入通道数的卷积核，以便与输入数据进行互相 关运算。假设输入的通道数为ci，那么卷积核的输入通道数也需要为ci。如果卷积核的窗口形状是kh ×kw，那 么当ci = 1时，我们可以把卷积核看作形状为kh × kw的二维张量。

​		然而，当ci > 1时，我们卷积核的每个输入通道将包含形状为kh × kw的张量。将这些张量ci连结在一起可以 得到形状为ci × kh × kw的卷积核。由于输入和卷积核都有ci个通道，我们可以对每个通道输入的二维张量和 卷积核的二维张量进行互相关运算，再对通道求和（将ci的结果相加）得到二维张量。这是多通道输入和多 输入通道卷积核之间进行二维互相关运算的结果。

![image-20240528105728927](https://raw.githubusercontent.com/kaisersama112/typora_image/master/image-20240528105728927.png)

​		下面我们将实现一个多输入通道互相关运算，我们所做的就是对每个通道执行互相关操 作，然后将结果相加。

```python
# 多输入互相关运算
import torch

# from d2l import torch as d2l

reduce_sum = lambda x, *args, **kwargs: x.sum(*args, **kwargs)


def corr2d(X, K):
    h, w = K.shape
    # print(K.shape)
    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            Y[i, j] = reduce_sum((X[i: i + h, j: j + w] * K))
    print(Y)
    return Y


def corr2d_multi_in(X, K):
    return sum(corr2d(x, k) for x, k in zip(X, K))


X = torch.tensor([
    [
        [0.0, 1.0, 2.0],
        [3.0, 4.0, 5.0],
        [6.0, 7.0, 8.0]
    ],
    [
        [1.0, 2.0, 3.0],
        [4.0, 5.0, 6.0],
        [7.0, 8.0, 9.0]
    ]
])
K = torch.tensor([
    [
        [0.0, 1.0],
        [2.0, 3.0]
    ],
    [
        [1.0, 2.0],
        [3.0, 4.0]
    ]
])

corr2d_multi_in(X, K)
```

```cmd
tensor([[19., 25.],
        [37., 43.]])
tensor([[37., 47.],
        [67., 77.]])
tensor([[ 56.,  72.],
        [104., 120.]])
```

### 4.2 多输入通道

​		在最流行的神经网络架构中，随着神经网络层数的加深，我们常会增加输 出通道的维数，通过减少空间分辨率以获得更大的通道深度。直观地说，我们可以将每个通道看作对不同特 征的响应。而现实可能更为复杂一些，因为每个通道不是独立学习的，而是为了共同使用而优化的。因此，多 输出通道并不仅是学习多个单通道的检测器。

​		用ci和co分别表示输入和输出通道的数目，并让kh和kw为卷积核的高度和宽度。为了获得多个通道的输出，我 们可以为每个输出通道创建一个形状为ci × kh × kw的卷积核张量，这样卷积核的形状是co × ci × kh × kw。在 互相关运算中，每个输出通道先获取所有输入通道，再以对应该输出通道的卷积核计算出结果。

​		 如下所示，我们实现一个计算多个通道的输出的互相关函数。

```python
def corr2d_multi_in_out(X, K):
    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)

# 通过将核张量K与K+1（K中每个元素加1）和K+2连接起来，构造了一个具有3个输出通道的卷积核。
K = torch.stack((K, K + 1, K + 2), 0)
print(K.shape)

corr2d_multi_in_out(X, K)
```

```cmd
torch.Size([3, 2, 2, 2])

tensor([[[ 56.,  72.],
         [104., 120.]],

        [[ 76., 100.],
         [148., 172.]],

        [[ 96., 128.],
         [192., 224.]]])
```

### 4.3 1*1  卷积层

​		1 × 1卷积，即kh = kw = 1，看起来似乎没有多大意义。毕竟，卷积的本质是有效提取相邻像素间的相关特 征，而1 × 1卷积显然没有此作用。尽管如此，1 × 1仍然十分流行，经常包含在复杂深层网络的设计中。下面， 让我们详细地解读一下它的实际作用。

![image-20240528144930501](https://raw.githubusercontent.com/kaisersama112/typora_image/master/image-20240528144930501.png)

​		上图展示了使用1×1卷积核与3个输入通道和2个输出通道的互相关计算。这里输入和输出具有相同的高度 和宽度，输出中的每个元素都是从输入图像中同一位置的元素的线性组合。我们可以将1 × 1卷积层看作在每 个像素位置应用的全连接层，以ci个输入值转换为co个输出值。因为这仍然是一个卷积层，所以跨像素的权 重是一致的。同时，1 × 1卷积层需要的权重维度为co × ci，再额外加上一个偏置。图中展示了互相关计算使用了具有3个输入通道和2个输出通道的 1 × 1 卷积核。其中，输入和输出具有相同的高 度和宽度。

```python
def corr2d_multi_in_out_1x1(X, K):
    c_i, h, w = X.shape  # 获取输入的通道数、高度和宽度
    c_o = K.shape[0]  # 获取输出通道数
    # 降维
    X = X.reshape((c_i, h * w))  # 将 X 的每个输入通道展平成一个向量
    # 卷积偏置
    K = K.reshape((c_o, c_i))  # 调整 K 的形状以便于矩阵乘法
    Y = torch.matmul(K, X)  # 进行矩阵乘法，得到输出张量
    return Y.reshape((c_o, h, w))  # 将输出张量恢复为 (c_o, h, w) 的形状

X = torch.normal(0, 1, (3, 3, 3))
K = torch.normal(0, 1, (2, 3, 1, 1))
print(X.shape)
print(K.shape)

```

```cmd
torch.Size([3, 3, 3])
torch.Size([2, 3, 1, 1])
```

```python
Y1 = corr2d_multi_in_out_1x1(X, K)
Y2 = corr2d_multi_in_out(X, K)
print(float(torch.abs(Y1 - Y2).sum()) < 1e-6) 
```

```cmd
True
```



## 5 汇聚层

​		通常当我们处理图像时，我们希望逐渐降低隐藏表示的空间分辨率、聚集信息，这样随着我们在神经网络中 层叠的上升，每个神经元对其敏感的感受野（输入）就越大。

​		而我们的机器学习任务通常会跟全局图像的问题有关（例如，“图像是否包含一只猫呢？”），所以我们最后一 层的神经元应该对整个输入的全局敏感。通过逐渐聚合信息，生成越来越粗糙的映射，最终实现学习全局表 示的目标，同时将卷积图层的所有优势保留在中间层。

​		此外，当检测较底层的特征时，，我们通常希望这些特征保持某种程度上的平 移不变性。例如，如果我们拍摄黑白之间轮廓清晰的图像X，并将整个图像向右移动一个像素，即Z[i, j] = X[i, j + 1]，则新图像Z的输出可能大不相同。而在现实中，随着拍摄角度的移动，任何物体几乎不可能发 生在同一像素上。即使用三脚架拍摄一个静止的物体，由于快门的移动而引起的相机振动，可能会使所有物 体左右移动一个像素（除了高端相机配备了特殊功能来解决这个问题）。

​		本节将介绍汇聚（pooling）层，它具有双重目的：降低卷积层对位置的敏感性，同时降低对空间降采样表示 的敏感性。

### 5.1 最大汇聚层和平均汇聚层

​		与卷积层类似，汇聚层运算符由一个固定形状的窗口组成，该窗口根据其步幅大小在输入的所有区域上滑动， 为固定形状窗口（有时称为汇聚窗口）遍历的每个位置计算一个输出。然而，不同于卷积层中的输入与卷积 核之间的互相关计算，汇聚层不包含参数。相反，池运算是确定性的，我们通常计算汇聚窗口中所有元素的 最大值或平均值。这些操作分别称为最大汇聚层（maximum pooling）和平均汇聚层（average pooling）。

​		在这两种情况下，与互相关运算符一样，汇聚窗口从输入张量的左上角开始，从左往右、从上往下的在输入 张量内滑动。在汇聚窗口到达的每个位置，它计算该窗口中输入子张量的最大值或平均值。计算最大值或平 均值是取决于使用了最大汇聚层还是平均汇聚层。

![image-20240528151642229](https://raw.githubusercontent.com/kaisersama112/typora_image/master/image-20240528151642229.png)

图：汇聚窗口形状为 2 × 2 的最大汇聚层。着色部分是第一个输出元素，以及用于计算这个输出的输入元 素: max(0, 1, 3, 4) = 4

​		汇聚窗口形状为p × q的汇聚层称为p × q汇聚层，汇聚操作称为p × q汇聚。

​		现在我们将使用卷积层的输出作为2 × 2最大汇聚的输入。设置卷积 层输入为X，汇聚层输出为Y。无论X[i, j]和X[i, j + 1]的值相同与否，或X[i, j + 1]和X[i, j + 2]的值 相同与否，汇聚层始终输出Y[i, j] = 1。也就是说，使用2 × 2最大汇聚层，即使在高度或宽度上移动一个 元素，卷积层仍然可以识别到模式。

```python
import torch
from torch import nn


def pool2d(X, pool_size, mode='max'):
    p_h, p_w = pool_size
    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            if mode == 'max':
                Y[i, j] = X[i:i + p_h, j:j + p_w].max()
            elif mode == 'avg':
                Y[i, j] = X[i:i + p_h, j:j + p_w].mean()
    return Y


X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])
print(pool2d(X, (2, 2)))
print(pool2d(X, (2, 2), mode='avg'))
```

```cmd
tensor([[4., 5.],
        [7., 8.]])
tensor([[2., 3.],
        [5., 6.]])
```

### 5.2 填充和步幅

​		与卷积层一样，汇聚层也可以改变输出形状。和以前一样，我们可以通过填充和步幅以获得所需的输出形状。 下面，我们用深度学习框架中内置的二维最大汇聚层，来演示汇聚层中填充和步幅的使用。我们首先构造了 一个输入张量X，它有四个维度，其中样本数和通道数都是1。

```python
X = torch.arange(16, dtype=torch.float32).reshape(1, 1, 4, 4)
# 汇聚窗口
pool2d = torch.nn.MaxPool2d(3)
print(pool2d(X))
```

```cmd
tensor([[[[10.]]]])
```

​		默认情况下，深度学习框架中的步幅与汇聚窗口的大小相同。因此，如果我们使用形状为(3, 3)的汇聚窗口， 那么默认情况下，我们得到的步幅形状为(3, 3)。

手动设置窗口大小和步幅

```python
pool2d = torch.nn.MaxPool2d(3, padding=1, stride=2)
print(pool2d(X))
pool2d = nn.MaxPool2d((2, 3), stride=(2, 3), padding=(0, 1))
print(pool2d(X))
```

```cmd
tensor([[[[ 5.,  7.],
          [13., 15.]]]])
          
tensor([[[[ 5.,  7.],
          [13., 15.]]]])
```



### 5.3 多个通道

​		在处理多通道输入数据时，汇聚层在每个输入通道上单独运算，而不是像卷积层一样在通道上对输入进行汇 总。这意味着汇聚层的输出通道数与输入通道数相同。下面，我们将在通道维度上连结张量X和X + 1，以构 建具有2个通道的输入。

```python
# 多个通道
X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))
X = torch.cat((X, X + 4), dim=0)
print(X.shape)
pool2d = torch.nn.MaxPool2d(3, padding=1, stride=2)
print(pool2d(X))
```

```cmd
torch.Size([2, 1, 4, 4])
tensor([[[[ 5.,  7.],
          [13., 15.]]],
        [[[ 9., 11.],
          [17., 19.]]]])
```



### 6.6 卷积神经网络（LeNet）

​		通过之前几节，我们学习了构建一个完整卷积神经网络的所需组件。之前我们将softmax回归模型和多层感知机模型应用于Fashion‐MNIST数据集中的服装图片。为了能够应用softmax回归 和多层感知机，我们首先将每个大小为28 × 28的图像展平为一个784维的固定长度的一维向量，然后用全连 接层对其进行处理。而现在，我们已经掌握了卷积层的处理方法，我们可以在图像中保留空间结构。同时，用 卷积层代替全连接层的另一个好处是：模型更简洁、所需的参数更少。

​		本节将介绍LeNet，它是最早发布的卷积神经网络之一，因其在计算机视觉任务中的高效性能而受到广泛关 注。这个模型是由AT&T贝尔实验室的研究员Yann LeCun在1989年提出的（并以其命名），目的是识别图像 (LeCun et al., 1998)中的手写数字。

​		当时，Yann LeCun发表了第一篇通过反向传播成功训练卷积神经网络的 研究，这项工作代表了十多年来神经网络研究开发的成果。 当时，LeNet取得了与支持向量机（support vector machines）性能相媲美的成果，成为监督学习的主流方 法。LeNet被广泛用于自动取款机（ATM）机中，帮助识别处理支票的数字。时至今日，一些自动取款机仍 在运行Yann LeCun和他的同事Leon Bottou在上世纪90年代写的代码呢！

## 6 LeNet

### 6.1 LeNet

LeNet（LeNet‐5）由两个部分组成： 

• 卷积编码器：由两个卷积层组成; 

• 全连接层密集块：由三个全连接层组成。

该架构如图所示。

![image-20240528155809979](https://raw.githubusercontent.com/kaisersama112/typora_image/master/image-20240528155809979.png)

​		每个卷积块中的基本单元是一个卷积层、一个sigmoid激活函数和平均汇聚层。请注意，虽然ReLU和最大汇 聚层更有效，但它们在20世纪90年代还没有出现。每个卷积层使用5 × 5卷积核和一个sigmoid激活函数。这 些层将输入映射到多个二维特征输出，通常同时增加通道的数量。第一卷积层有6个输出通道，而第二个卷 积层有16个输出通道。每个2 × 2池操作（步幅2）通过空间下采样将维数减少4倍。卷积的输出形状由批量大 小、通道数、高度、宽度决定。

​		为了将卷积块的输出传递给稠密块，我们必须在小批量中展平每个样本。换言之，我们将这个四维输入转换 成全连接层所期望的二维输入。这里的二维表示的第一个维度索引小批量中的样本，第二个维度给出每个样 本的平面向量表示。LeNet的稠密块有三个全连接层，分别有120、84和10个输出。因为我们在执行分类任务， 所以输出层的10维对应于最后输出结果的数量。

```python
import torch
from torch import nn
class CustomNet(nn.Module):
    def __init__(self):
        super(CustomNet, self).__init__()
        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)
        self.sigmoid1 = nn.Sigmoid()
        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)
        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)
        self.sigmoid2 = nn.Sigmoid()
        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.sigmoid3 = nn.Sigmoid()
        self.fc2 = nn.Linear(120, 84)
        self.sigmoid4 = nn.Sigmoid()
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = self.conv1(x)
        x = self.sigmoid1(x)
        x = self.pool1(x)
        x = self.conv2(x)
        x = self.sigmoid2(x)
        x = self.pool2(x)
        x = self.flatten(x)
        x = self.fc1(x)
        x = self.sigmoid3(x)
        x = self.fc2(x)
        x = self.sigmoid4(x)
        x = self.fc3(x)
        return x

net = nn.Sequential(nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),
                    nn.AvgPool2d(kernel_size=2, stride=2),
                    nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),
                    nn.AvgPool2d(kernel_size=2, stride=2),
                    nn.Flatten(),
                    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),
                    nn.Linear(120, 84), nn.Sigmoid(),
                    nn.Linear(84, 10)
                    )
X = torch.rand(size=(1, 1, 28, 28), dtype=torch.float32)
print(net(X).shape)
net1 = CustomNet()
X = torch.rand(size=(1, 1, 28, 28), dtype=torch.float32)
print(net1(X).shape)
```

```cmd
torch.Size([1, 10])
torch.Size([1, 10])
```

​		请注意，在整个卷积块中，与上一层相比，每一层特征的高度和宽度都减小了。第一个卷积层使用2个像素的 填充，来补偿5 × 5卷积核导致的特征减少。相反，第二个卷积层没有填充，因此高度和宽度都减少了4个像 素。随着层叠的上升，通道的数量从输入时的1个，增加到第一个卷积层之后的6个，再到第二个卷积层之后 的16个。同时，每个汇聚层的高度和宽度都减半。最后，每个全连接层减少维数，最终输出一个维数与结果 分类数相匹配的输出。

### 6.2 模型训练

​		由于我们将实现多层神经网络，因此我 们将主要使用高级API。以下训练函数假定从高级API创建的模型作为输入，并进行相应的优化。我们使用在之前介绍的Xavier随机初始化模型参数。与全连接层一样，我们使用交叉熵损失函数和小批量随机梯度 下降。

```python
# 模型训练
import torch
from torch import nn
from d2l import torch as d2l

net = nn.Sequential(nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),
                    nn.AvgPool2d(kernel_size=2, stride=2),
                    nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),
                    nn.AvgPool2d(kernel_size=2, stride=2),
                    nn.Flatten(),
                    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),
                    nn.Linear(120, 84), nn.Sigmoid(),
                    nn.Linear(84, 10)
                    )

batch_size = 1024
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)
print(len(train_iter))


def evaluate_accuracy_gpu(net, data_iter, device=None):  #@save
    """使用GPU计算模型在数据集上的精度"""
    if isinstance(net, nn.Module):
        net.eval()  # 设置为评估模式
    if not device:
        device = next(iter(net.parameters())).device
    # 正确预测的数量，总预测的数量
    metric = d2l.Accumulator(2)
    with torch.no_grad():
        for X, y in data_iter:
            if isinstance(X, list):
                # BERT微调所需的（之后将介绍）
                X = [x.to(device) for x in X]
            else:
                X = X.to(device)
            y = y.to(device)
            metric.add(d2l.accuracy(net(X), y), y.numel())
    return metric[0] / metric[1]


def train(net, train_iter, test_iter, num_epochs, lr, device):
    def init_weights(m):
        if type(m) == nn.Linear or type(m) == nn.Conv2d:
            nn.init.xavier_uniform_(m.weight)

    # 初始化权重
    net.apply(init_weights)
    print(f"train on {device}")
    net.to(device)
    # 定义学习率
    optimizer = torch.optim.SGD(net.parameters(), lr=lr)
    # 定义损失
    loss = nn.CrossEntropyLoss()
    animator = d2l.Animator(xlabel="epoch", xlim=[1, num_epochs],
                            legend=['train loss', 'train acc', 'test acc'])
    timer, num_batches = d2l.Timer(), len(train_iter)
    for epoch in range(num_epochs):
        metric = d2l.Accumulator(3)
        net.train()
        for i, (X, y) in enumerate(train_iter):
            timer.start()
            # 梯度归零
            optimizer.zero_grad()
            X, y = X.to(device), y.to(device)
            y_hat = net(X)
            # 计算误差
            l = loss(y_hat, y)
            # 反向计算 自动微分
            l.backward()
            # 参数更新
            optimizer.step()
            # 不需要进行网络参数的更新就不需要后向传播
            with torch.no_grad():
                metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])
            timer.stop()
            train_l = metric[0] / metric[2]
            train_acc = metric[1] / metric[2]
            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:
                animator.add(epoch + (i + 1) / num_batches,
                             (train_l, train_acc, None))
        test_acc = evaluate_accuracy_gpu(net, test_iter)
        animator.add(epoch + 1, (None, None, test_acc))
    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '
          f'test acc {test_acc:.3f}')
    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '
          f'on {str(device)}')


lr, num_epochs = 0.9, 100
train(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())

```

```cmd
loss 0.308, train acc 0.886, test acc 0.874
184100.0 examples/sec on cuda:0
```

![image-20240529104356381](https://raw.githubusercontent.com/kaisersama112/typora_image/master/image-20240529104356381.png)

​				• 卷积神经网络（CNN）是一类使用卷积层的网络。

​				• 在卷积神经网络中，我们组合使用卷积层、非线性激活函数和汇聚层。 

​				• 为了构造高性能的卷积神经网络，我们通常对卷积层进行排列，逐渐降低其表示的空间分辨率，同时增 加通道数。 

​				• 在传统的卷积神经网络中，卷积块编码得到的表征在输出之前需由一个或多个全连接层进行处理。 

​				• LeNet是最早发布的卷积神经网络之一。

​		上一章我们介绍了卷积神经网络的基本原理，本章将介绍现代的卷积神经网络架构，许多现代卷积神经网 络的研究都是建立在这一章的基础上的。在本章中的每一个模型都曾一度占据主导地位，其中许多模型都 是ImageNet竞赛的优胜者。ImageNet竞赛自2010年以来，一直是计算机视觉中监督学习进展的指向标。

这些模型包括：

​		• AlexNet。它是第一个在大规模视觉竞赛中击败传统计算机视觉模型的大型神经网络； 

​		• 使用重复块的网络（VGG）。它利用许多重复的神经网络块； 

​		• 网络中的网络（NiN）。它重复使用由卷积层和1 × 1卷积层（用来代替全连接层）来构建深层网络; 

​		• 含并行连结的网络（GoogLeNet）。它使用并行连结的网络，通过不同窗口大小的卷积层和最大汇聚层 来并行抽取信息； 

​		• 残差网络（ResNet）。它通过残差块构建跨层的数据通道，是计算机视觉中最流行的体系架构； 

​		• 稠密连接网络（DenseNet）。它的计算成本很高，但给我们带来了更好的效果。

​		虽然深度神经网络的概念非常简单——将神经网络堆叠在一起。但由于不同的网络架构和超参数选择，这些 神经网络的性能会发生很大变化。本章介绍的神经网络是将人类直觉和相关数学见解结合后，经过大量研究 试错后的结晶。我们会按时间顺序介绍这些模型，在追寻历史的脉络的同时，帮助培养对该领域发展的直觉。 这将有助于研究开发自己的架构。例如，本章介绍的批量规范化（batch normalization）和残差网络（ResNet） 为设计和训练深度神经网络提供了重要思想指导。