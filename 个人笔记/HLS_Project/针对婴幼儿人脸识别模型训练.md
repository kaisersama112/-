该模型基于 ArcFace 算法实现
## 模型讲解
[insightface/recognition/arcface_torch at master · deepinsight/insightface](https://github.com/deepinsight/insightface/tree/master/recognition/arcface_torch)
[【机器学习】详解 ArcFace-CSDN博客](https://blog.csdn.net/qq_39478403/article/details/116788113)

使用深度卷积神经网络 (DCNN) 进行大规模人脸识别的特征学习中，主要挑战之一在于 设计适当的损失函数以增强判别能力。Center Loss 会惩罚欧式空间中深层特征及其对应的类中心之间的距离，以实现 类内紧凑性 (intra-class compactness)。 SphereFace 假定 最后一个全连接层中的线性变换矩阵 可用作角度空间 (angular space) 中类中心的表示，并以乘法方式惩罚深度特征及其相应权重 (weights) 之间的角度 (angles)。近期，一种流行的研究方向是将 margins 纳入已建立的损失函数中，以最大程度地提高人脸类别可分性 (face class separability)。本文提出了一个 加性角度边距损失 (Additive Angular Margin Loss, ArcFace)，以获取用于人脸识别的高判别度特征 (highly discriminative features)。

## 数据集构建

### 数据集标注



### 公开数据集

- ["]  [MS1MV2](https://github.com/deepinsight/insightface/tree/master/recognition/_datasets_#ms1m-arcface-85k-ids58m-images-57) (87k IDs, 5.8M images)  
- ["]  [MS1MV3](https://github.com/deepinsight/insightface/tree/master/recognition/_datasets_#ms1m-retinaface) (93k IDs, 5.2M images)  
- ["]  [Glint360K](https://github.com/deepinsight/insightface/tree/master/recognition/partial_fc#4-download) (360k IDs, 17.1M images)  
- ["]  [WebFace42M](https://github.com/deepinsight/insightface/blob/master/recognition/arcface_torch/docs/prepare_webface42m.md) (2M IDs, 42.5M images)  

注意： 如果您想使用 DALI 进行数据读取，请在使用前使用脚本 'scripts/shuffle_rec.py' 来随机播放 InsightFace 样式 rec。 

例：`python scripts/shuffle_rec.py ms1m-retinaface-t1`

您将获得 “shuffled_ms1m-retinaface-t1” 文件夹，其中 “train.rec” 文件中的样本被随机排列。

### 自定义数据集格式

首先，人脸图像需要检测和对齐，以确保为处理做好适当的准备。此外，有必要将具有相同 ID 的每个人的面部图像放入单独的文件夹中，以便正确组织。

```
# directories and files for yours datsaets
/image_folder
├── 0_0_0000000
│   ├── 0_0.jpg
│   ├── 0_1.jpg
│   ├── 0_2.jpg
│   ├── 0_3.jpg
│   └── 0_4.jpg
├── 0_0_0000001
│   ├── 0_5.jpg
│   ├── 0_6.jpg
│   ├── 0_7.jpg
│   ├── 0_8.jpg
│   └── 0_9.jpg
├── 0_0_0000002
│   ├── 0_10.jpg
│   ├── 0_11.jpg
│   ├── 0_12.jpg
│   ├── 0_13.jpg
│   ├── 0_14.jpg
│   ├── 0_15.jpg
│   ├── 0_16.jpg
│   └── 0_17.jpg
├── 0_0_0000003
│   ├── 0_18.jpg
│   ├── 0_19.jpg
│   └── 0_20.jpg
├── 0_0_0000004


# 0) Dependencies installation
pip install opencv-python
apt-get update
apt-get install ffmpeg libsm6 libxext6  -y


# 1) create train.lst using follow command
python -m mxnet.tools.im2rec --list --recursive train image_folder

# 2) create train.rec and train.idx using train.lst using following command
python -m mxnet.tools.im2rec --num-thread 16 --quality 100 train image_folder
```

最后，您将获得三个文件：train.lst、train.rec 和 train.idx，其中 train.idx 和 train.rec 用于训练。


## 训练记录

训练模型，使用配置文件的路径执行 `train_v2.py` 脚本。下面的示例命令演示了执行分布式训练的过程
### 1. 要在一个 GPU 上运行：

```shell
python train_v2.py configs/ms1mv3_r50_onegpu
```

注意：  
不建议使用单个 GPU 进行训练，因为这可能会导致训练时间延长和性能欠佳。为了获得最佳结果，我们建议使用多个 GPU 或一个 GPU 集群。
### 2. 要在具有 8 个 GPU 的计算机上运行：

```shell
torchrun --nproc_per_node=8 train_v2.py configs/ms1mv3_r50
```
### 3. 要在 2 台每台计算机（每台计算机具有 8 个 GPU）上运行：

节点 0：

```shell
torchrun --nproc_per_node=8 --nnodes=2 --node_rank=0 --master_addr="ip1" --master_port=12581 train_v2.py configs/wf42m_pfc02_16gpus_r100
```

节点 1：

```shell
torchrun --nproc_per_node=8 --nnodes=2 --node_rank=1 --master_addr="ip1" --master_port=12581 train_v2.py configs/wf42m_pfc02_16gpus_r100
```

### 4. 在批量大小为 24k 的机器上运行 ViT-B：


```shell
torchrun --nproc_per_node=8 train_v2.py configs/wf42m_pfc03_40epoch_8gpu_vit_b
```

## 侧端模型格式转换

### pth 转换 onnx


### onnx 转换 ncnn

借用 onnx2ncnn.exe 示例 `onnx2ncnn lw50.onnx lw50.param lw50.bin`


## 移动端量化


```
## Basic
- [ ] to-do
- [/] incomplete
- [x] done
- [-] canceled
- [>] forwarded
- [<] scheduling

## Extras
- [?] question
- [!] important
- [*] star
- ["] quote
- [l] location
- [b] bookmark
- [i] information
- [S] savings
- [I] idea
- [p] pros
- [c] cons
- [f] fire
- [k] key
- [w] win
- [u] up
- [d] down
- [D] draft pull request
- [P] open pull request
- [M] merged pull request
```


