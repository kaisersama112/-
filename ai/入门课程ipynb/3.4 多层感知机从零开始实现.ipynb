{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7f690d48a283a4b",
   "metadata": {},
   "source": [
    "为了与之前softmax回归获得的结果进行比较， 我们将继续使用Fashion-MNIST图像分类数据集。\n",
    "\n",
    "## 初始化模型参数\n",
    "\n",
    "回想一下，Fashion-MNIST中的每个图像由 28*28=784个灰度像素值组成。 所有图像共分为10个类别。 忽略像素之间的空间结构， 我们可以将每个图像视为具有784个输入特征 和10个类的简单分类数据集。 首先，我们将实现一个具有单隐藏层的多层感知机， 它包含256个隐藏单元。 注意，我们可以将这两个变量都视为超参数。 通常，我们选择2的若干次幂作为层的宽度。 因为内存在硬件中的分配和寻址方式，这么做往往可以在计算上更高效。\n",
    "我们用几个张量来表示我们的参数。 注意，对于每一层我们都要记录一个权重矩阵和一个偏置向量。 跟以前一样，我们要为损失关于这些参数的梯度分配内存。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bfa9fbed1d7e47b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T07:11:54.687146Z",
     "start_time": "2024-01-29T07:11:54.280048500Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Matplotlib requires numpy>=1.17; you have 1.16.6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01md2l\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m torch \u001b[38;5;28;01mas\u001b[39;00m d2l\n\u001b[0;32m      5\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m\n\u001b[0;32m      6\u001b[0m train_iter, test_iter \u001b[38;5;241m=\u001b[39m d2l\u001b[38;5;241m.\u001b[39mload_data_fashion_mnist(batch_size)\n",
      "File \u001b[1;32mF:\\minconda\\envs\\d2l\\lib\\site-packages\\d2l\\torch.py:35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib_inline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend_inline\n\u001b[0;32m     38\u001b[0m d2l \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;18m__name__\u001b[39m]\n",
      "File \u001b[1;32mF:\\minconda\\envs\\d2l\\lib\\site-packages\\matplotlib\\__init__.py:208\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m parse_version(module\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m parse_version(minver):\n\u001b[0;32m    204\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatplotlib requires \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    205\u001b[0m                               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 208\u001b[0m \u001b[43m_check_versions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;66;03m# The decorator ensures this always returns the same handler (and it is only\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# attached once).\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache()\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ensure_handler\u001b[39m():\n",
      "File \u001b[1;32mF:\\minconda\\envs\\d2l\\lib\\site-packages\\matplotlib\\__init__.py:204\u001b[0m, in \u001b[0;36m_check_versions\u001b[1;34m()\u001b[0m\n\u001b[0;32m    202\u001b[0m module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(modname)\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parse_version(module\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m parse_version(minver):\n\u001b[1;32m--> 204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatplotlib requires \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    205\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: Matplotlib requires numpy>=1.17; you have 1.16.6"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "\n",
    "num_inputs, num_outputs, num_hiddens = 784, 10, 256\n",
    "\n",
    "w1 = nn.Parameter(torch.randn(\n",
    "    num_inputs, num_hiddens, requires_grad=True) * 0.01)\n",
    "b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=True))\n",
    "w2 = nn.Parameter(torch.randn(\n",
    "    num_hiddens, num_outputs, requires_grad=True) * 0.01)\n",
    "b2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=True))\n",
    "\n",
    "params = [w1, b1, w2, b2]\n",
    "\n",
    "\n",
    "# 激活函数\n",
    "def relu(x):\n",
    "    a = torch.zeros_like(x)\n",
    "    return torch.max(x, a)\n",
    "\n",
    "\n",
    "# 模型\n",
    "\"\"\"\n",
    "因为我们忽略了空间结构， 所以我们使用reshape将每个二维图像转换为一个长度为num_inputs的向量。 只需几行代码就可以实现我们的模型。\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def net(x):\n",
    "    x = x.reshape((-1, num_inputs))\n",
    "    h = relu(torch.dot(x, w1) + b1)\n",
    "    return (torch.dot(h, w2) + b2)\n",
    "\n",
    "\n",
    "# 损失函数\n",
    "\"\"\"\n",
    "之前我们已经从零实现过softmax函数， 因此在这里我们直接使用高级API中的内置函数来计算softmax和交叉熵损失。 回想一下我们之前对这些复杂问题的讨论。\n",
    "\"\"\"\n",
    "loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "# 训练\n",
    "\n",
    "num_epochs, lr = 10, 0.1\n",
    "updeter = torch.optim.SGD(params, lr=lr)\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, updeter)\n",
    "\n",
    "# 为了对学习到的模型进行评估，我们将在一些测试数据上应用这个模型。\n",
    "d2l.predict_ch3(net, test_iter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c5a64a7a641adf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facc429854ff54f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56df5cce65168531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f9b36fa64b5dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52791d34cc220f34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
