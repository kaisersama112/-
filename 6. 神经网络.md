# 神经网络

## 1. 神经元模型

​	“**神经网络是由具有适应性的简单单元组成的广泛并行互联的网络，它的组织能够模拟生物神经系统对真实世界物体所做出的交互反应**。”神经网络最基本的成分是神经元（neuron）模型

### 1.1 M-P神经元模型

​	在这个模型中，神经元接收到来自n个其他神经元传递过来的输入信号。这些输入信号通过带全权重的连接（connection）进行传递，神经元接收到的总输入值将与神经元的阈值进行比较，然后通过**“激活函数”**（activation function）处理以产生神经元的输出。

![image-20240228171754260](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240228171754260.png)

​	理想中的激活函数是如图所示的阶跃函数

![image-20240228172156759](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240228172156759.png)

​	它将输入值映射为输出值“0”或“1”,显然“1”对应于神经元兴奋，“0”对应于神经元抑制，然而，阶跃函数具有不连续，不光滑等不好的性质。因此实际采用**Sigmoidj函数**作为激活函数。典型的激活函数如图所示，他把可能在较大范围内变化的输入值挤压到（0，1）输出值范围内，因此有时也称为**“挤压函数”**（squashing function）。

![image-20240228172321323](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240228172321323.png)

## 2. 感知机与多层网络

**感知机**（Perceceotron）由两层神经元组成，如图，输入层接收外层输入信号后传递给输出层，输出层是M-P神经元，亦称“阈值逻辑单元”（threshold logic unit）。

![image-20240228172651587](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240228172651587.png)

感知机能容易的实现逻辑与，或，非运算，注意到![image-20240228172733602](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240228172733602.png),假定f是sigmoid函数。

![image-20240228172839472](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240228172839472.png)

![image-20240228172846790](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240228172846790.png)

​	一般地，给定训练数据集，权重W1（i=1,2,....,n）![image-20240229100541435](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240229100541435.png)以及阈值0可通过学习得到。法制0可看作一个固定输入为-1.0的”哑节点“（dummy node）所对应的连接权重wn+1这样，权重和阈值的学习就可以统一为权重的学习，感知机学习规则：对训练样例（x,y)，若当前感知机的输出为y`,则感知机权重将这样调整。

![image-20240229100446056](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240229100446056.png)

![image-20240229100557869](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240229100557869.png)

![image-20240229100610664](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240229100610664.png)

![image-20240229101637548](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240229101637548.png)

![image-20240229101649812](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240229101649812.png)

![image-20240229102125887](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240229102125887.png)

![image-20240229102202859](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240229102202859.png)

## 3. 误差逆传播算法（error backpropagation）

​	多层网路的学习能力比单层感知机强得多，预训练多层网络，简单感知机学习规则显然不够，需要更强大的学习算法，误差逆传播（error backpropagation ,简称BP）算法就是其中最接触的代表，它是迄今最成功的神经网络学习算法，现实任务中使用神经网络时候，大多在使用BP算法进行训练，值得指出的是，BP算法不仅可用于多层前馈神经网络，还可用于其他类型的神经网络，如训练递归神经网络，但通常说”BP网络“时，一般是指用BP算法训练的多层前馈神经网络。

![image-20240229103827863](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240229103827863.png)

![image-20240229103837705](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240229103837705.png)

![image-20240229103945471](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240229103945471.png)

![image-20240229104813085](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240229104813085.png)

![image-20240229110406577](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240229110406577.png)

![image-20240229111228445](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240229111228445.png)

![image-20240229112256574](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240229112256574.png)

**上述计算步骤通过链式求导实现对神经元权重进行更新**

### 3.1 均方误差 (MSE)

![image-20240229105409670](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240229105409670.png)

​	均方误差（MSE）是度量预测值于真实值之间的差的平方均值，它只考虑误差的平均大小，不考虑其方向，但由于经过平方，让真实值偏离较多的预测值比偏离较小的预测值受到的更多的权重惩罚。再加上MSE的数学特性很好，这使得计算梯度变得更加容易。

​	下图是MSE 函数的图像，其中目标值是 100，预测值的范围从 -10000 到 10000，Y 轴代表的 MSE 取值范围是从0 到正无穷，并且在预测值为 100 处变得最小。

![MSE 函數的圖像](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-8.png)

**又被称为L2 损失 或 L2范式损失/平方损失**

### 3.2 梯度下降算法（Gradient Descent）

​	![image-20240229104727858](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240229104727858.png)

![image-20240229104746246](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240229104746246.png)

## 4. 全局最小与局部最小

![image-20240229113129809](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240229113129809.png)

![image-20240229113239778](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240229113239778.png)

![image-20240229113344962](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240229113344962.png)

## 5.  其他常见神经网络

### 5.1 RBF神经网络

#### 径向基函数

$$
径向基函数是取值仅仅依赖于离原点距离的实值函数即φ(x)=φ(∣∣x∣∣)(也可以是离任意点的 \\
距离,距离一般使用欧式距离[欧式径向基函数],也可以是其他距离函数),任何满足该特性的函 \\
数都φ都叫做径向基函数,通常定义为空间中任一点x到某一中心c之间区民距离的单调函数 \\
常见的径向基函数包括(定义r=∣x−c i​∣∣c i​ O称为径向基函数的扩展函数(方差),它反应了函数图像的宽度,σ越小,宽度越窄,函数越具有选择性) \\
Gauss(高斯)函数:φ(r)=exp(− 2σ 2 r 2 ​ )反演S型函数:φ(r)= 1+exp( σ 2 r 2 ​ 1​) \\
拟多二次函数:φ(r)= (r 2+σ 2) 21​ 1​
$$

![image](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsassetsv2-001abd0f31fdfa9c3d4c62e87e2f7c60_720w.webp)

![img](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsv2-8555687647e71365e5d2cbadea69b048_720w.webp)	

![img](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsv2-001abd0f31fdfa9c3d4c62e87e2f7c60_720w.webp)

​	RBF（Radial Basis Function ,径向基函数）网络是一种单隐层前馈神经网络，它是由径向基函数作为隐层神经元激活函数，而输出层则是对隐藏神经元输出的线性组合，假定输入为d维向量x，输出为实值，则RBF网络可表示为

![image-20240229114900280](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240229114900280.png)

![image-20240229114932785](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240229114932785.png)

### 5.2 ART神经网络

![image-20240229114958749](https://raw.githubusercontent.com/kaisersama112/typora_image/master/assetsimage-20240229114958749.png)

