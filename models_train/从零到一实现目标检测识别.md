# ocr识别流程

​	自然场景的文本识别是指在无约束的环境中处理图像文本信息.当前研究通常将自然场景的文本识别分为两个步骤:文本检测(text detection)和文本识别(text recognition）

### 1. 文本检测

​	根据检测文本对象的不同可以将基于深度学习的方法划分为**基于回归的文本检测方法和基于分割的文本检测方法两大类**

#### 1.1 基于回归的文本检测方法

​	![image.png](./assets/bVc225k.png)

​	基于深度学习的基于回归的自然场景文本检测方法可分为**两阶段**和**单阶段**的方法。

这里我们就只讲解单阶段方法：

​	很多单阶段的目标检测器如YOLO(you only look once) 系列(Redmon 等，2016; Redmon和Farhadi，2017) 和SSD(single shot multibox detector)(Liu 等，2016a)也被学者们应用于自然场景文本检测。Gupta 等人(2016)基于YOLO 模型，对不同尺度的图像使用全卷积网络(Long 等，2015)定位文本的位置。基于SSD 的方法则有以下的一些工作。

Liao 等人(2017)提出了Text-Boxes，该算法针对自然场景文本的特性，设置了适应性的锚点(Anchor)，考虑到文本长宽比与通用目标差别过大便采用了长条形的卷积核，它能对水平文本取得不错的检测性能。这些学者进一步提出TextBoxes ++ (Liao 等人，2018a)，增加了角度预测以适应多方向文本的检测。He 等人(2017b)加入了文本注意力机制，通过强化文本部分的特征加强其分类和边界框回归，同时他们设计了一个多级特征融合模块以适应文本的尺度变化。

Liu 和Jin (2017)也是基于相同的框架提出了深度匹配先验网络(deep matching prior network， DMPNet)，首次使用四边形锚点框来替换原来的矩形锚点框，实现了多方向文本检测。Liao 等人(2018b)针对多方向文本这一问题，使用了方向响应网络(oriented response network，ORN)取代融合SSD中不同尺度特征的侧边连接。ORN 可以提取旋转的文本特征以适应不同方向的文本实例，然后在每个侧边连接提取特征后进行分类和边界框回归。

![image.png](./assets/bVc226T.png)

除了基于SSD 和YOLO 这类需要锚点框的单阶段方法之外，还有很多是借助文本的一些几何属性进行建模并利用全卷积神经网络的单阶段文本检测方法。

Zhou 等人(2017)借鉴了DenseBox(Huang等，2015)的架构和U-Net(Ronneberger 等，2015)的特性提出了EAST(efficient and accurate scene text detector)算法，结构如图所示。

它先在每个像素位置预测是否有文本，如果有则直接预测该像素点对应文本实例的得分图和边界坐标。He 等人(2017c)提出的DDR(deep direct regression)算法思想和EAST 相似，不过DDR 是直接学习4 个边界点对于有文本像素点作为文本实例中心点的偏移量，而EAST 是回归点到边框的上下左右距离。

类似的方法还有Xue 等人(2018)提出的Border，不过它除了进行文本和非文本分类以及边框回归的同时，还增加了对**4 条文本框边界的学习和预测**。

Wang 等人(2018b) 提出了一个实例变换网络( instance transformation network， ITN)去学习自然场景文本的几何属性表达，以**适应任意四边形文本行的检测**。

![image.png](./assets/bVc226V.png)

**针对不规则文本的检测**，Long 等人(2018)提出的TextSnake 是首个单阶段解决此类问题的工作。
它先利用一个全卷积神经网络预测文本区域、文本的中心线以及几何属性(角度、半径等)，然后通过这些属性重建整个文本实例。

Zhang 等人(2019a)提出的LOMO(look more than once)是在EAST 算法思想的基础上额外增加了一个迭代优化模块和形状表征模块，分别**加强对长文本以及对不规则文本的检测**。

而Wang 等人(2019a) 提出的SAST(singleshot arbitrarily-shaped text detector) 同样也是EAST的演进版本，他们也借鉴了TextSnake 的思想，在直接回归边界框的同时加入了对文本一些几何特征的预测(文本中心线区域、文本边界偏置和文本中心点偏置等)，使之能适用于不规则的文本检测。

考虑到文本多尺度的问题，Xue 等人(2019)提出了多尺度形状回归网络(multi-scale regression，MSR) 去检测不同尺度的任意形状文本。MSR 分别预测文本中心区域、中心区域的点到最近边界的横向和纵向距离，最后通过后处理得到文本边框。

##### Text-Boxes算法特点



![img](./assets/webp.webp)

SSD

![img](./assets/watermark.png)

​	TextBox 的架构如图 所示。它继承了流行的 VGG-16 架构（Simonyan 和 Zisserman 2014），将层从 conv1 1 保留到 conv4 3。VGG-16的最后两个全连接层通过参数下采样转换为卷积层（Liu等人，2016）。它们后面是一些额外的卷积层和池化层，即 conv6 到 pool11。

多个输出层（我们称之为文本框层）插入到最后一个和一些中间卷积层之后。它们的输出被聚合并经过非极大值抑制 （NMS） 过程。输出层也是卷积层。总而言之，TextBox 仅由卷积层和池化层组成，因此是完全卷积的。它可以在训练和测试中适应任意大小的图像。



###### VGG-16深度神经网络

![img](./assets/v2-084124cbdf8b933df4543efa1d980ce2_720w.webp)

**1.vgg-block****内的卷积层都是同结构的** 

意味着输入和输出的尺寸一样，且卷积层可以堆叠复用，其中的实现是通过统一的size为3×3的kernel size + stride1 + padding(same)实现。

**2.maxpool层将前一层(vgg-block层)的特征缩减一半** 

使得尺寸缩减的很规整，从224-112-56-28-14-7。其中是通过pool size2 + stride2实现

**3.****深度较深，参数量够大** 

较深的网络层数使得训练得到的模型分类效果优秀，但是较大的参数对训练和模型保存提出了更大的资源要求。

**4.****较小的filter size/kernel size**

 这里全局的kernel size都为3×3，相比以前的网络模型来说，尺寸足够小。

![img](./assets/v2-3b6f9a5dfdb8be26fc5747da3ecf2484_r.jpg)

**第1层\**输入层\**：** 输入为224×224×3 三通道的图像。

**第2层\**vgg block层\**：** 输入为224×224×3，经过64个kernel size为3×3×3的filter,stride = 1，padding=same卷积后得到shape为224×224×64的block层（指由conv构成的vgg-block）。

**第3层Max-pooling层：** 输入为224×224×64，经过pool size=2,stride=2的减半池化后得到尺寸为112×112×64的池化层

**第4层\**vgg block层\*：\*** 输入尺寸为112×112×64，经128个3×3×64的filter卷积，得到112×112×128的block层。

***第5层\*Max-pooling\*层\**：\***输入为112×112×128，经pool size = 2,stride = 2减半池化后得到尺寸为56×56×128的池化层。

**第6层\**vgg block\**层：** 输入尺寸为56×56×128，经256个3×3×128的filter卷积，得到56×56×256的block层。

**第7层\**Max-pooling\**层：** 输入为56×56×256，经pool size = 2,stride = 2减半池化后得到尺寸为28×28×256的池化层。

**第8层\**vgg block层：\**** 输入尺寸为28×28×256，经512个3×3×256的filter卷积，得到28×28×512的block层。

**第9层\**Max-pooling\**层：** 输入为28×28×512，经pool size = 2,stride = 2减半池化后得到尺寸为14×14×512的池化层。

**第10层\**vgg block层：\**** 输入尺寸为14×14×512，经512个3×3×512的filter卷积，得到14×14×512的block层。

**第11层\**Max-pooling\**层：** 输入为14×14×512，经pool size = 2,stride = 2减半池化后得到尺寸为7×7×512的池化层。该层后面还隐藏了flatten操作，通过展平得到7×7×512=25088个参数后与之后的全连接层相连。

**第12～14层Dense层：** 第12~14层神经元个数分别为4096,4096,1000。其中前两层在使用relu后还使用了Dropout对神经元随机失活，最后一层全连接层用softmax输出1000个分类。

**名称解释:**

**卷积层**：通过指定类型的卷积核对图像进行规则遍历，从而可以实现让图像特征区域提取

**池化层**：负责将高维数据通过一系列方法对其维度进行下降

**激活层**：通过对输入进行指定处理实现然后输出，增加网络的非线性能力

**全连接层**：在整个卷积神经网络中起到“**分类器**”的作用（输出不同类的概率），上图中的 TextBoxes Layers层主要就是做的这个功能

这一段看不懂没关系 你只需要知道不管是**TextBoxes**算法还是**SSD算法**他们都是基于卷积神经网络实现,将一个识别问题转换成一个分类回归问题。

现在我们回过来看Text-box这个网络结构

![img](./assets/watermark.png)

**论文链接地址：extension://amkbmndfnliijdhojkpoglbnaaahippg/pdf/index.html?file=https%3A%2F%2Farxiv.org%2Fpdf%2F1611.06779.pdf**



Text-boxes整体网络结构如上面所示，在**VGG-16**的基础上新增9个额外的卷积层，共28层，类似于**SSD（也是一个很经典的目标检测算法）**，在不同的层之后都有输出层，称之为 text-box layers， text-box layers的输出通道是72（2个通道预测分数，4个通道预测位置偏移量，共12个anchor(这里说的anchor就是SSD中讲的default box)，所以共(2+4)*12=72个通道），整合所有的 text-box layers的输出结果后再使用**NMS**处理，就得到了最终的结果。

###### TextBox 文本框层：

 TextBox 的关键组件。文本框层同时预测文本存在和边界框，并根据其输入特征图进行调节。在每个地图位置，它以卷积方式将分类分数和偏移量输出到其关联的默认框。假设图像和特征图大小分别为 （w， h） 和 （w， h）。在与默认框 b= （x， y， w， h） 关联的地图位置 （i， j） 上，文本框图层预测 （∆x， ∆y， ∆w， ∆h， c） 的值，指示以置信度 c 检测到框 b = （x， y， w， h），其中

Text-box 层的输出由两部分构成，一部分是目标区域的位置，另一部分是该目标区域关于是文字和背景的概率

Text-box层特征图的深度是72，每个区域有12个比例不同、位置不同的默认框(default boxes)，对于每个框需要预测4个值，即预测框与默认框的偏差，对于每一个默认框，还有softmax进行二分类得到的2个概率值，即该区域属于背景和文字的概率，因此总共是72-d的向量。

![image-20240128185153948](./assets/image-20240128185153948.png)

![img](./assets/v2-5c7520da516f5d705ffcf2a6a2fc1a31_720w.png)



###### NMS：

NMS全称非极大值抑制用处很广泛，不管是边缘检测、目标检测，都具有很广泛的应用

NMS算法一般是为了去掉模型预测后的多余框，其一般设有一个nms_threshold=0.5，具体的**实现思路**如下：

1. 选取这类box中scores最大的哪一个，记为box_best，并保留它
2. 计算box_best与其余的box的**IOU**（区域交并比）
3. 如果其IOU>0.5了，那么就舍弃这个box（由于可能这两个box表示同一目标，所以保留分数高的哪一个）
4. 从最后剩余的boxes中，再找出最大scores的哪一个，如此循环往复

###### 卷积神经网络结构：

![img](./assets/v2-35fd5c7a2b0a911a85e52559f3cd3826_720w.png)

![img](./assets/v2-73af0123f03eb3fed8751bfc92d2473e_r.jpg)

![img](./assets/1e609caab8ed4494a92a7c8ef6c8fb30.gif)

上图是只有黑白颜色的灰度图，而更普遍的图片表达方式是RGB颜色模型，即红、绿、蓝三原色的色光以不同的比例相加，以产生多种多样的色光。RGB颜色模型中，单个矩阵就扩展成了有序排列的三个矩阵，也可以用三维tensor去理解。

其中的每一个矩阵又叫这个图片的一个channel（通道），宽, 高, 深来描述。

![img](./assets/c1cf86811b904e20928fba24372c92db.png)

​	卷积操作是指将一个可移动的小窗口（称为数据窗口，如下图绿色矩形）与图像进行逐元素相乘然后相加的操作。这个小窗口其实是一组固定的权重，它可以被看作是一个特定的滤波器（filter）或**卷积核**。这个操作的名称“卷积”，源自于这种元素级相乘和求和的过程。这一操作是卷积神经网络名字的来源。

​	卷积操作就是用一个可移动的小窗口来提取图像中的特征，这个小窗口包含了一组特定的权重，通过与图像的不同位置进行卷积操作，网络能够学习并捕捉到不同特征的信息。文字解释可能太难懂，下面直接上动图：

![img](./assets/a1e1905ac9b04cd2ac539c417c1e42fd.gif)

这张图中蓝色的框就是指一个数据窗口，红色框为卷积核（滤波器），最后得到的绿色方形就是卷积的结果（数据窗口中的数据与卷积核逐个元素相乘再求和）

![img](./assets/ea3d406273ef408a9a0e1a0903cf24d5.png)


**步长stride**：每次滑动的位置步长。

 **卷积核的个数**：决定输出的depth厚度。同时代表卷积核的个数。

**填充值zero-padding**：在外围边缘补充若干圈0，方便从初始位置以步长为单位可以刚好滑倒末尾位置，通俗地讲就是为了总长能被步长整除。
![img](./assets/ff805f9e3c1e4cc3bb37b4abb87cb09b.png)



#### 1.2 基于分割的文本检测方法



### 2. 方向检测及其矫正



### 3. 文本识别



### 4. 关键信息抽取



### 5. SER + RE(关系映射)